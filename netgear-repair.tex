\documentclass{sigcomm-alternate}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{color}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{gnuplot-lua-tikz}
\usepackage{adjustbox}
\usepackage{fp}

\newcommand{\FIXME}[1]{{\color{red}\{FIXME #1\}}}

\lstset{language=C}
\definecolor{dkgreen}{rgb}{0,0.5,0}
\definecolor{dkred}{rgb}{0.5,0,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\lstset{basicstyle=\ttfamily\bfseries\footnotesize,
  morekeywords={virtualinvoke,fucompp,fnstsw,fldl,fstpl,movl},
  keywordstyle=\color{blue},
  ndkeywordstyle=\color{red},
  commentstyle=\color{dkred},
  stringstyle=\color{dkgreen},
  numbers=left,
  numberstyle=\ttfamily\footnotesize\color{gray},
  stepnumber=1,
  numbersep=10pt,
  backgroundcolor=\color{white},
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
  xleftmargin=.23in
}
\date{\today}
\title{Automated Repair of Exploits in NETGEAR Router Binary}

\begin{document}

\maketitle
\usetikzlibrary{arrows,decorations,decorations.pathreplacing,shapes}

\begin{abstract}
% WRW thinks the old Abstract put too much emphasis on Vigilante / Dawn
% Song research. In the modern era, the question isn't whether or not to
% release the exploit, but whether or not to release the patch (which can
% be reverse-engineered to get the exploit, which is then used against
% those who haven't applied the patch.)
The speed with which researchers and vendors respond to security
vulnerabilities is critical, especially after exploits have been discovered.
The situation is especially dire for end users who lack
product source code and typically must wait for a patch to be released
by the vendor, or in some cases using
%must typically fall back on techniques such as
signature generation and packet filtering, rather than addressing the
root cause. We propose an alternative in which newly discovered
exploits drive an automated repair technique capable of patching
vulnerabilities even without access to source code or special
information from the software vendor.

Using an evolutionary automated software repair approach, we focus on
the special requirements of security repairs to binaries.  Extensions
to earlier work include: adapting the method to handle stripped ELF
files, operating without fault localization information, and devising
a repair algorithm that can work without a pre-existing regression
test suite.

We demonstrate this approach by patching recently discovered exploits
in version 4 of NETGEAR's WNDR3700 wireless router \emph{before}
NETGEAR publicly addressed the exploits. To the authors' knowledge,
NETGEAR had not patched these exploits at the time of submission.
Even without any regression tests to guide the search, we find that 80\% of
repairs of the example exploits retain program functionality.
% In my example repairs it took at most two user-written tests to find
% an acceptable repair.
When a few user-created tests of required functionality are incorporated, 100\% do so.
% We discuss the feasibility and utility of this technique for the security
% community.

\end{abstract}

\section{Introduction}
\label{sec-1}
% WRW really thinks that "full disclosure" is not the fight we want to be
% making, since we'll lose. The setup for your experiments is: the exploit
% is already available, the company is slow, what can end-users do to
% protect themselves? 
Security exploits pose significant economic and social risks. By Symantec's
count 5,291 vulnerabilities were reported in 2012
alone~\cite{symantec2013threat}. Despite this, human developers take
28-FIXME-Wes
% ERIC can't find any good number for this.  In looking for this
% number I got on the whole to-disclose-or-not line of papers that led
% to the previous abstract.
days, on average, to address security-critical defects. Even
when informed, developers do not always act immediately:  In one example,
Oracle reportedly waited months after researchers privately reported a bug
in Java while thousands of users were attacked before releasing a
patch~\cite{greenberg2012oracle}.  Compounding this, a survey of 2,000
human-written operating system repairs found that 14--24\% were
incorrect~\cite{fixes-become-bugs}---the official patch may be late, wrong,
or both.  

We propose a new option in which reproducible exploits are used to drive an
automatic repair technique. This technique operates even when developer
source code and test suites are not available, and is thus more immediately
applicable. A user-produced patch may be installed for internal protection,
redistributed with the exploit (reporting an exploit with a patch in hand
has been shown to reduce the total number of attacks~\cite{arora2006does}),
or sent to the software vendor to reduce development time for the official
patch~\cite{weimer06}.

In recent years, a variety of automated methods for program repair have 
successfully repaired defects in real software
% FIXME-Wes: What is "par"?  You mentioned it during your visit as
%            well, but I can't find the citation.
(e.g.,~\cite{clearview,genprog-tse-journal,par,nguyen2013semfix}).
Automated repair methods based on evolutionary computation have also
repaired defects directly in x86 and ARM ELF files, without access to
program source code~\cite{schulte2013embedded}.  This prior work,
however, relies on a regression test suite to define the required
functionality, or informal specification, of the program under repair.
Here we consider a setting in which neither source code nor test
suites are available, and there is no special information or
cooperation from the vendor.  

%We propose a new evolutionary program repair technique adapted to
%the non-vendor-level repair of security vulnerabilities: neither source
%code nor test suites nor any 

We demonstrate the feasibility of our automated repair technique by
patching multiple security vulnerabilities in the widely popular NETGEAR
WNDR3700 wireless router before NETGEAR publicly addressed the
exploits.  Although previous evolutionary program repair techniques
explicitly require access to a regression test suite, we explore the
feasibility of performing repair without any such test suite and find
that for our example exploit, regression test suites are most often
not necessary. In addition, we find that the complexity of security
vulnerabilities requires iterative applications of repair actions
within a single evolutionary run.

In the remainder of this paper we review two recent exploits to the
NETGEAR WNDR3700 (Section \ref{sec-2}); demonstrate the feasibility
of running the NETGEAR firmware in a VM sandbox (Section \ref{sec-3-1});
review our novel techniques of automated program repair (Sections
\ref{sec-3-2} and \ref{on-demand-regression}); and evaluate the effectiveness of this
technique and the quality of the repairs it generates (Section
\ref{repair-demonstration}).

The main  contributions of this short paper are;
\begin{itemize}
\item A novel automated repair technique suitable for non-vendor repairs to
security vulnerabilities (not requiring source code, test cases, or fault
localization), and 
\item An application of the approach to a real-world unpatched
security exploit, resulting in
\item The first demonstration of multiple iterative repairs in a single
run of the evolutionary repair algorithm.
\end{itemize}

In the pursuit of reproducible
research~\cite{buckheit1995wavelab,mesirov2010accessible} and to encourage
others to patch
future discovered exploits, we have released a companion open source
repository.\footnote{\url{https://github.com/eschulte/netgear-repair}}
This repository contains the instructions, source
code, and tooling needed to extract, execute and repair the binary
NETGEAR router image vulnerabilities, as well as the data used for the
analyses and figures reported  in this paper.
\iffalse
Additionally, the analysis performed in this document and all
supporting figures may be automatically regenerated from new
experimental data using the Org-mode reproducible research framework
\cite{schulte2012reproducible-research}.
\fi

By demonstrating a method for automatically patching vulnerable closed source
applications without waiting for software vendors to respond, we hope to encourage
users to patch important vulnerabilities quickly and researchers to
release patches simultaneously
with exploit announcements.

\section{Description of Exploits}
\label{sec-2}
We describe repairs of two current exploits in version 4 of the NETGEAR WNDR3700
wireless router. The popularity of this router implies that vulnerable
systems are widespread in the absence of a published patch. For example, the
``shodan''\footnote{\url{http://www.shodanhq.com/search?q=wndr3700v4+http}}
device search engine alone returned hundreds of vulnerable publicly
accessible WNDR3700 routers at the time of writing.
Both exploits exist in the router's internal web server in a binary
executable named \texttt{net-cgi}, and both are related to how
\texttt{net-cgi} handles authentication~\cite{zcutlip}.

The vendor-deployed binary is insecure in at least two ways: 
\begin{enumerate}
\item Any URI starting with the string ``{\tt BRS}'' bypasses authentication.

\item Any URI including the substring ``\path{unauth.cgi}'' or\\
  ``\path{securityquestions.cgi}'' bypass authentication. This applies
  even to requests of the form
  \url{http://router/page.html?foo=unauth.cgi}, meaning that the
  vulnerability effectively applies to all internal webpages.
\end{enumerate}

Many administrative pages start with the ``{\tt BRS}'' string, providing
attackers with access to personal information such as user's
passwords, and by accessing the page
\url{http://router/BRS_02_genieHelp.html} attackers can
disable authentication completely and permanently
across reboots.

\section{Repair Technique}
\label{sec-3}

Our repair technique for this vulnerability consists of three stages:
\begin{enumerate}
\item Extract the binary executable from the firmware and reproduce
the exploit (Section~\ref{sec-3-1}).
\item Apply evolutionary program repair techniques based on mutations
  to the stripped (without symbols or section tables) MIPS ELF binary
  (Section~\ref{sec-3-2}).
\item Construct test cases lazily, as needed, to improve the quality of
unsatisfactory candidate repairs (Section~\ref{on-demand-regression}). 
\end{enumerate} 

The first step in repairing the \texttt{net-cgi} executable is to extract
it and the router file system from the firmware image distributed by
NETGEAR.  Using the extracted filesystem and executable we construct a test
harness that can exercise the exploits in \texttt{net-cgi}.  This test harness
is used by the repair algorithm to evaluate candidate repairs and to
identify when repairs to the exploits have been found.

\subsection{Firmware Extraction and Virtualization}
\label{sec-3-1}
NETGEAR distributes firmware with a full system image for the
WNDR3700 router which includes the router file system that has the
vulnerable \texttt{net-cgi} executable. 
The file system was extracted using the 
\texttt{binwalk}\footnote{\url{http://binwalk.org}} firmware extraction
tool, which scans the binary data in the raw monolothic firmware file,
searching for signatures
identifying embedded data sections,
%The \texttt{binwalk} tool
%includes rules for identifying and extracting common embedded data
%types, 
including {\tt squashfs}\cite{lougher2006squashfs} which
holds the router's file system.

The router runs on a big-endian MIPS architecture, requiring emulation
on most desktop system to safely reproduce the exploit and evaluate
candidate repairs. We used the QEMU system
emulator~\cite{bellard2005qemu} to emulate the MIPS architecture in a
lightweight manner with Debian Linux also run in
emulation.  The extracted router file system is copied into the
emulated MIPS Linux system.  A number of special directories (e.g.,
\path{/proc/}, \path{/dev/} etc.) are mounted inside the extracted
file system and bound to the corresponding directories on the virtual
machine.  At this point, commands can be executed in an environment
that closely approximates the execution environment of the NETGEAR
router by using the \texttt{chroot} command to confine executable access
to within the extracted NETGEAR file system. Additional minor
adjustments are described in \url{http://eschulte.github.io/netgear-repair/INSTRUCTIONS.html}.

At this point the NETGEAR router can be run under virtualization.  In
particular, the router's web interface can be accessed either using an
external web browser or the \texttt{net-cgi} executable can be called
directly from the command line.

\subsection{Automated Program Repair and ELF Files}
\label{sec-3-2}

We use evolutionary computation methods
\cite{forrest2009genetic,genprog-tse-journal,le2012representations,legoues2011systematicstudy}
to search for small changes to existing programs that eliminate
undesired buggy behavior.  This process typically has access to the
source code of the original program, which is first transformed into
an abstract syntax tree and then iteratively modified using random
\emph{mutations} and \emph{crossovers} to generate program variants.
Each variant is evaluated in a process called fitness evaluation by
running it against the program's existing regression test suite and at
least one additional test that demonstrates the undesired behavior.

The repair algorithm constructs a population of 512 program variants,
each with one or more random mutations.  This population evolves
through an iterated process of mutation and evaluation until a version
of the original program is found that repairs the bug.  That is, the
repair must satisfy the regression test suite and avoid the buggy
behavior.

In earlier versions of the algorithm, execution traces were collected
during program execution and used as a form of \emph{fault
  localization} to bias random mutations towards the parts of the
program most likely to contain the bug.  Our decision not to use fault
localization is explained in Section \ref{no-fault-localization}.

This basic repair algorithm was modified in several ways to address
the unique scenario of a user attempting to repair a faulty binary
executable (Section \ref{mutate-mips}), without access to a regression
test suite (Section \ref{on-demand-regression}), and without the fault
localization optimization.

\subsubsection{Challenge: Mutating Stripped Binaries}
\label{mutate-mips}

Executable programs for Unix and embedded system are commonly distributed
as ELF (Executable and Linking Format)~\cite{tis1995tool} files. 
Each ELF file contains a number of headers
and tables containing administrative data, and sections holding
program code and data.  The three main administrative elements of an
ELF file are the ELF header, the section table and the program table
(see Figure \ref{elf}).  The ELF header points to the section table and the
program table, the section table holds information on the layout of
sections in the ELF file on disk, and the program table holds
information on how to copy sections from disk into memory for program
execution.

\begin{figure}[htb]
  \centering
  \adjustbox{width=0.4\textwidth}{
\begin{tikzpicture}
  % ELF File
  \node[draw, rectangle, minimum height=11.5em, minimum width=8em] (whole) at (0,0) {};
  \node[minimum width=8em] (header) at (0,1.65) {ELF Header};
  \draw[thick] (header.south west) -- (header.south east);
  \node[minimum width=8em] (st) at (0,1) {Section Table};
  \node[minimum width=8em] (body1) at (0,0.25) {...};
  \node[minimum width=8em] (body2) at (0,-0.25) {Section Data};
  \node[minimum width=8em] (body3) at (0,-0.75) {...};
  \node[minimum width=8em] (pt) at (0,-1.5) {Program Table};
  % External Users
  \node[draw, ellipse, fill=blue!20, minimum height=3em, minimum width=6em] (linker) at (-3,1) {Linker};
  \node[draw, ellipse, fill=red!20, minimum height=3em, minimum width=6em]  (memory) at (3,-1.5) {Memory};
  % Arrows to Users
  \draw[->,thick] (st.west) to (linker.east);
  \draw[->,thick] (pt.east) to (memory.west);
  % Section Table Arrows
  \draw[->,thick,densely dotted,bend right=90] (body1.east) to (st.east);
  \draw[->,thick,densely dotted,bend right=90] (body2.east) to (st.east);
  \draw[->,thick,densely dotted,bend right=90] (body3.east) to (st.east);
  % Program Table Arrows
  \draw[->,thick,densely dotted,bend right=90] (body1.west) to (pt.west);
  \draw[->,thick,densely dotted,bend right=90] (body2.west) to (pt.west);
  \draw[->,thick,densely dotted,bend right=90] (body3.west) to (pt.west);
\end{tikzpicture}
}
\caption{\label{elf}Sections and their uses in an Executable and
  Linking Format (ELF) file.}
\end{figure}

Our approach to repairing stripped MIPS ELF files extends
previous work on the automated repair of unstripped Intel and ARM
files~\cite{schulte2013embedded}. 
Mutation and crossover operations are used to modify the
execution behavior of the ELF file.  In this case, however, the \texttt{net-cgi} file
does not include information on which
the earlier work relied.
 Although the majority of ELF files include all three of the elements
shown in Fig. \ref{elf}, only the ELF Header is guaranteed to exist in
all cases.  In executable ELF files, the program table is also required, and
similarly, in linkable files the section table is required.

Previous work used the section table and section name string table to
locate the \texttt{.text} section of the ELF file where program code
is normally stored.  The data in the \texttt{.text} section were then
coerced into a linear array of assembly instructions (the
\emph{genome}) on which the mutation operations were defined.  Our
extension removes this dependence by concatenating the data of every
section in the program table that has a ``loadable'' type to produce
the genome.  These are the sections whose data are loaded into memory
during program execution.

Mutation operations must change program data without corrupting the
structure of the file or breaking the many addresses hard coded into
the program data itself (e.g., as destinations for conditional jumps).
In general, it is impossible to distinguish between an integer literal
and an address in program data, so the mutation operations are
designed to preserve operand absolute sizes and offsets within the ELF
program data.  This requirement is easily met because every argumented
assembly instruction in the MIPS RISC architecture is one word
long~\cite{hennessy1982mips}.  ``Single point crossover'' is used to
combine two ELF files.  An offset in the program data is selected,
then bytes from one file are taken up to that offset and bytes from
the other file taken after that offset.  This form of crossover works
especially well because all ELF files will have similar total length and
offsets. The mutation and crossover operations used to modify stripped
MIPS ELF files are shown in Figure~\ref{mutation-ops}.

\tikzstyle{asmrow} = [rectangle, draw, minimum width=2em, minimum height=1em]
\begin{figure}[htb]
  \centering
\begin{tikzpicture}
  % Mutation
  \foreach \x in {-3.5,-2.5,-0.5,0.5,2.5,3.5}{
    \foreach \y in {-0.8,-0.4,0,0.4,0.8}{
      \node[asmrow,fill=green!40] at (\x,\y) {};
    }
  }
  % Replace
  \node at (-3,1.25) {Replace};
  \node[asmrow,fill=yellow!20] (c-from) at (-3.5,0.4) {};
  \node[asmrow,fill=blue!60] at (-3.5,-0.4) {};
  % replace-after
  \node[asmrow,fill=yellow!20] at (-2.5,0.4) {};
  \node[asmrow,fill=yellow!20] (c-to) at (-2.5,-0.4) {};
  \node[asmrow,fill=green!40]  at (-2.5,-0.8) {};
  % Delete
  \node at (0,1.25) {Delete};
  \node[asmrow,fill=red!40] (d-from) at (-0.5,0) {};
  % delete-after
  \node[asmrow,fill=white] (d-to) at (0.5,0) {\scriptsize{0x0}};
  % Swap
  \node at (3,1.25) {Swap};
  \node[asmrow,fill=yellow!20] (s1-from) at (2.5,0.4) {};
  \node[asmrow,fill=blue!60] (s2-from) at (2.5,-0.4) {};
  % swap-after
  \node[asmrow,fill=blue!60] (s2-to) at (3.5,0.4) {};
  \node[asmrow,fill=yellow!20] (s1-to) at (3.5,-0.4) {};
  % arrows
  \draw[->,thick] (c-from.east) to (c-to.west);
  \draw[->,thick] (d-from.east) to (d-to.west);
  \draw[->,thick] (s1-from.east) to (s1-to.west);
  \draw[->,thick] (s2-from.east) to (s2-to.west);
  % Crossover
  \node at (0,-1.7) {One Point Crossover};
  \foreach \x in {-1.5,1.5}{
    \foreach \y in {-3.8,-3.4,-3,-2.6,-2.2}{
      \node[asmrow,fill=green!40] at (\x,\y) {};
    }
  }
  \foreach \x in {-0.5}{
    \foreach \y in {-3.8,-3.4,-3,-2.6,-2.2}{
      \node[asmrow,fill=blue!60] at (\x,\y) {};
    }
  }
  \draw[->,thick] (-2,-3.2) to (2,-3.2);
  \node[asmrow,fill=blue!60] at (1.5,-3.4) {};
  \node[asmrow,fill=blue!60] at (1.5,-3.8) {};
\end{tikzpicture}
\caption{Mutation and Crossover operations for stripped MIPS ELF files.  The
  program data is represented as a fixed length array of single-word
  sections.  These operators change these sections maintaining length
  and offset in the array.}
  \label{mutation-ops}
\end{figure}

\subsection{On-Demand Regression Testing}
\label{on-demand-regression}

Our approach to automated program repair relies on the ability to
assess the validity of any candidate repair.  The mutations are random
in the sense that they do not take into account or preserve the
semantics of the program.  They are more likely to create new bugs
or exploits than they are to repair undesired behavior, and the method
requires an evaluation scheme to distinguish between these cases.

Instead of relying on a pre-existing regression test suite, we assume
only that a demonstration of the exploit provides a single available
test.  By mutating programs without the safety net of a regression
test suite, the evolved ``repairs'' often introduce significant
regressions.  However, by applying a minimization process after the
primary repair is identified, these regressions are removed in the
majority of cases (Section \ref{minimization}).  The minimization
reduces the difference between the evolved repair and the original
program to as few edits as possible using Delta
Debugging~\cite{delta}.  The interactive phase of the repair algorithm
asks the user to identify any regressions that remain after the Delta
Debugging step.  High level pseudocode for the repair algorithm is
show in Figure \ref{lazy-algorithm}.

Our method is thus an interactive repair process in which the
algorithm searches for a patch that 
passes every available test (starting with only the exploit), and then
minimizes it using Delta Debugging.  In a third step,
the user evaluates its suitability.  If the repair is accepted, the process
terminates. Otherwise, the user supplies a new regression test that the repair
fails (a witness to its unsuitability) and the process repeats. 
In Section \ref{repair-demonstration} we find that 80\% of our
attempts to repair the NETGEAR WNDR3700 exploits did not require any
user-written regression tests.

\begin{figure}[htb]
\begin{algorithmic}[1]
\small
\item[{\textbf{Input: }} {Vulnerable Program, $\mathsf{original}$ : $ELF$}]
\item[{\textbf{Input: }} {Exploit Tests, $\mathsf{exploits}$ : $[ELF \rightarrow Fitness]$}]
\item[{\textbf{Input: }} {Interactive Check, $\mathsf{good-enough}$ : $ELF \rightarrow [ELF \rightarrow Fitness]$}]
\item[{\textbf{Output: }} {Patched version of Program}] 
  \STATE {\bf let} $new \leftarrow \mathsf{null}$ 
  \STATE {\bf let} $fitness \leftarrow \mathsf{null}$ 
  \STATE {\bf let} $suite \leftarrow \mathsf{exploits}$ 
  \REPEAT {
    \STATE {\bf let} $\mathsf{full} \leftarrow \mathsf{evolutionarySubroutine}(\mathsf{original}, \mathsf{suite})$
    \STATE $new \leftarrow \mathsf{minimize()}$
    \STATE {\bf let} $newRegressionTests \leftarrow \mathsf{good-enough}(\mathsf{new})$ 
    \STATE $\mathsf{suite} \leftarrow \mathsf{suite} ++ \mathsf{newRegressionTests}$
  }
  \UNTIL { $length(\mathsf{newRegressionTests}) \equiv 0$ }
  \RETURN { $\mathsf{new}$ }
\end{algorithmic}
\caption{\label{lazy-algorithm}High-level Pseudocode for interactive
lazy-regression-testing repair algorithm.}
\end{figure}

The \texttt{evolutionarySubroutine} in Figure \ref{lazy-algorithm} has
the same high level organization as previous work~\cite{genprog-tse-journal},
but it uses a \emph{steady state}
evolutionary computational algorithm~\cite{Luke2013Metaheuristics} for
reduced memory usage and ease of parallelization of fitness evaluation.
High level pseudocode for the \texttt{evolutionarySubroutine} is shown in
Figure \ref{evolutionary-subroutine}.

\begin{figure}[htb]
\begin{algorithmic}[1]
\small
\item[{\textbf{Input: }} {Vulnerable Program, $\mathsf{original}$ : $ELF$}]
\item[{\textbf{Input: }} {Test Suite, $\mathsf{suite}$ : $[ELF \rightarrow Fitness]$}]
\item[{\textbf{Parameters: }} {$populationSize$, $tournamentSize$, $crossRate$}]
\item[{\textbf{Output: }} {Patched version of Program}] 
  \STATE {\bf let} $fitness \leftarrow \mathsf{evaluate}(\mathsf{original}, \mathsf{suite})$ 
  \STATE {\bf let} $pop \leftarrow \mathsf{populationSize}$ copies of $\langle \mathsf{original}, \mathsf{fitness} \rangle$
  \REPEAT {
    \IF {$\mathsf{Random}() < CrossRate$}
      \STATE {\bf let} $\mathsf{p_{1}} \leftarrow \mathsf{crossover}(\mathsf{tournament}(\mathsf{pop}, \mathsf{tounamentSize}, +))$
      \STATE {\bf let} $\mathsf{p_{2}} \leftarrow \mathsf{crossover}(\mathsf{tournament}(\mathsf{pop}, \mathsf{tounamentSize}, +))$
      \STATE {\bf let} $\mathsf{p} \leftarrow \mathsf{crossover}(\mathsf{p_{1}}, \mathsf{p_{2}})$
    \ELSE
      \STATE $p \leftarrow \mathsf{tournament}(\mathsf{pop}, \mathsf{tounamentSize}, +)$
    \ENDIF
    \STATE {\bf let} $p' \leftarrow \mathsf{Mutate}(p)$
    \STATE {\bf let} $fitness \leftarrow \mathsf{evaluate}(\mathsf{suite}, \mathsf{p'})$
    \STATE $\mathsf{incorporate}(pop,\langle p', \mathsf{Fitness}(\mathsf{Run}(p')) \rangle)$
    \IF {$\mathsf{length}(\mathsf{pop}) > \mathsf{maxPopulationSize}$}
      \STATE $\mathsf{evict}(\mathsf{pop}, \mathsf{tournament}(\mathsf{pop}, \mathsf{tounamentSize}, -))$
    \ENDIF
  }
  \UNTIL { $\mathsf{fitness} > \mathsf{length}(\mathsf{suite})$ }
  \RETURN { $\mathsf{p'}$ }
\end{algorithmic}
\caption{\label{evolutionary-subroutine}High-level Pseudocode for the
steady state parallel evolutionary repair subroutine.}
\end{figure}

Note that every time the user rejects the
solution returned by \texttt{evolutionarySubroutine}, the evolved and
minimized solution is discarded and a new population is generated by
again copying the original by the \texttt{evolutionarySubroutine}.  Unlike
most applications of EC, but as in nature, our EC of extant programs
always starts from a point in the fitness landscape which is very
nearly optimal.  This is because the original program is not a random
combinations of instructions, but is instead 
a highly engineered solution to the program fitness
landscape.  This algorithmic choice acknowledges the fitness of the
original program, and for this reason gives it primacy over the
evolved solutions of previous iterations (which may well have evolved
into fitness valleys as in run 8 Table \ref{minimized-stats}).

\section{Repair Demonstration}
\label{repair-demonstration}

We first describe the experimental setup we used to test the
repair technique on the NETGEAR WNDR3700 exploit (Section
\ref{methodology}).  We then analyze the results of ten repair
attempts (Section \ref{analysis}).

\subsection{Methodology}
\label{methodology}
We demonstrate our technique by patching two NETGEAR WNDR3700
exploits.  All repairs were performed on a server-class machine with
32 physical Intel Xeon 2.60GHz cores, Hyper-Threading and 120 GB of
Memory.  We first describe the test harness used to assess the fitness
of each program variant (Section
\ref{fitness-evaluation}), then we give the parameters used in the experiments
(Section \ref{sec:parameters}).

\subsubsection{Fitness Evaluation}
\label{fitness-evaluation}
We used 32 QEMU virtual machines, each
running Debian Linux with the NETGEAR router firmware environment
available inside of a \texttt{chroot}.  The repair algorithm itself
uses 32 threads for parallel fitness evaluation.  Each thread is
paired with a single QEMU VM on which it tests fitness.

The test framework includes both a host and a guest test script.  The
host script runs on the server performing repair and the guest script
runs in a MIPS virtual machine.  The host script copies a
variant of the \texttt{net-cgi} executable to the guest VM where the
guest test script executes \texttt{net-cgi} the command line and
reports a result of {\sc Pass}, {\sc Fail}, or {\sc Error} for each
test.  These values are then used to calculate the variant's scalar
fitness.

{\sc Pass} indicates that the program completed successfully and
produced the correct result, {\sc Fail} indicates that the program
completed successfully but produced an incorrect result, and {\sc
  Error} indicates that the program execution did not complete
successfully due to early termination (e.g., because of a segfault) or
by a non-zero ``errno'' exit value.

\subsubsection{Repair Parameters}
\label{sec:parameters}
Repair used the following parameters.  The maximum population size was
512 individuals, selection is performed using a tournament size of two
\footnote{When the fitness of all variants in the population has been
  evaluated, the fitness values are used to select one individual for
  subsequent modifications in the next generation.  We use
  \emph{tournament selection} where each tournament chooses a subset
  of two (the tournament size) randomly from the population and the
  individual with higher fitness wins the tournament and is copied
  into the population.}.  When the population overflows the maximum
population size, an individual is selected for eviction using a
negative tournament of size two.  Newly selected individuals are
crossed over two-thirds of the time.

These parameters differ significantly from those used in previous
evolutionary computation (EC)
repair algorithms
(e.g.,~\cite{forrest2009genetic,legoues2011systematicstudy,le2012representations}).
Specifically, we use larger populations (512 instead of 40 individuals),
running for many more fitness evaluations ($\leq$100,000 instead of
$\leq$400).  However, the parameters used here are in line with
those used in other EC parameters given the size of the NETGEAR cgi
module, and they
allow our technique to succeed withouth the help of fault localization
information.

The increased memory required by the larger population size is offset
by the use of a steady-state~\cite{Luke2013Metaheuristics} EC
algorithm, and the increased computational demand of the greater
number of fitness evaluations is offset by parallelization of fitness
evaluation.

\subsection{Analysis of Repairs}
\label{analysis}

We report results for the time typically taken to generate a repair
(Section \ref{runtime}), the effect of eliminating fault localization
(Section \ref{no-fault-localization}), and the impact of the
minimization process (Section \ref{minimization}), both with respect
to the size of the repair in terms of byte difference from the
original and in terms of the fitness improvement.  Finally we
demonstrate how multiple repairs can be discovered iteratively by the
repair process (Section \ref{iterative-repair}).

\subsubsection{Repair Runtime}
\label{runtime}
Both the quality or ``coverage'' (number of bytes of program data
exercised by a test suite) and the time spent on fitness evaluation
(Fig. \ref{ts-cov-rt-w-min}) varies with the size of the regression
test suite, which ranges from only the vulnerability test ('3 tests')
to increasing portions of the user-generated regression test suite
until the entire regression test suite is used ('11 tests').  For
\texttt{net-cgi}, the additional coverage of the larger test suites is
not sufficient to justify the increased running time or the time
required to compose the regression tests.  We believe this is true of
many programs which implement a single main use case and corresponding
path of execution.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.46\textwidth]{ts-cov-and-runtime-w-min.pdf}  
  \caption{Test suite coverage and runtime with locations of minimized
    edits.  Four test suites are shown ranging from 3 tests (exploit
    tests only) to 11 tests (all exploit and author-generated regression tests).  The
    coverage of each suite is shown as the byte offsets of the samples
    collected during the execution of the tests, which are plotted
    vertically.  The horizontal position of each suite's plot shows
    the runtime of the suite in seconds.  The location of every edit
    in a minimized successful repair is plotted as a horizontal line.
    Only 2 of the 22 minimized edit locations are within 3 bytes of a
    sample from any suite. }
  \label{ts-cov-rt-w-min}
\end{figure}

In 8 of the 10 attempted repairs the three exploit tests alone were
sufficient, and the third phase of user-generated tests was not required.  This corresponds to the first
group of traces labeled ``3 tests'' in Fig. \ref{ts-cov-rt-w-min}.

In these cases the repair process took an average of ~36,000 total fitness
evaluations requiring on average 86.6 minutes to find a repair using 32
virtual machines for parallelized fitness evaluation.

\subsubsection{No Fault Localization}
\label{no-fault-localization}

In addition to adding an extra and sometimes burdensome step to the
repair process, the use of fault localization has the more serious
problem of sometimes over-constraining the search operators (mutation
and crossover) \cite{schulte2013optimization}, preventing the
discovery of valid repairs.

One of the NETGEAR exploits exemplifies this problem, where fault
localization prevents the repair process from succeeding.  As shown in
Figure \ref{ts-cov-rt-w-min}, many of the program locations where successful
repairs made edits were not included in the trace information.
In fact, only 2 of the 22 program locations modified by successful repairs 
were within 3 instructions of the execution traces.  Although
surprising, this result suggests that 
previous evolutionary program repair techniques, which confine edit
operations to execution traces, are likely unable to repair the NETGEAR
bugs.
% FIXME Wes:
% Do you agree with this statement?  Another way to state this is that
% regular genprog will never mutate some relevant portions of the
% program program, e.g., data such as structs which can not be labeled
% using execution traces.

\subsubsection{Minimization Impact}
\label{minimization}

In some cases the initial suggested repair, known as the
\emph{primary} repair, was not satisfactory.  For
example, suggested repairs sometimes worked when \texttt{net-cgi} was
called directly on the command line but not through the embedded
$\mu$HTTPd webserver,\footnote{\url{http://wiki.openwrt.org/doc/uci/uhttpd}}
or the repaired file failed to serve pages not used in the
exploit test.  However, Table \ref{minimized-stats} shows that in most
cases the minimized version of the repair was satisfactory,
successfully passing all hand-written regression tests, even those not used
during the repair process. 

\begin{table}[htb]
\centering
\begin{tabular}{rrrrrr}
Run  & Fit Evals & Full Diff & Min Diff & Full Fit & Min Fit \\
\toprule
0    & 90405     & 500       & 2        & 8        & 22      \\
1    & 17231     & 134       & 3        & 22       & 22      \\
2    & 26879     & 205       & 2        & 21       & 22      \\
3    & 23764     & 199       & 2        & 19       & 22      \\
4    & 47906     & 319       & 2        & 6        & 6       \\
5    & 13102     & 95        & 2        & 16       & 22      \\
6    & 76960     & 556       & 3        & 17       & 22      \\
7    & 11831     & 79        & 3        & 20       & 22      \\
8    & 2846      & 10        & 1        & 14       & 14      \\
9    & 25600     & 182       & 2        & 21       & 22      \\
\bottomrule
mean & 33652.4   & 227.9     & 2.2      & 16.4     & 19.6    \\
\end{tabular}
\caption{\label{minimized-stats}Difference and functionality of
evolved repair before and after minimization.  In these columns ``Full''
refers to evolved solutions before minimization and ``Min'' refers to
post-minimization solutions.  Columns labeled ``Diff'' report the number
of unified diff windows against the original program data. The columns
labeled ``Fit'' report the fitness measured with a full regression test
suite including the exploit tests with a maximum fitness of 22.}
\end{table}

As shown in Table \ref{minimized-stats}, the initial evolved repair
differed from the original at over 200 locations on average in the ELF
program data, while the minimized repairs differed at only 1--3
locations on average.  This great discrepancy is due to the
accumulation of candidate edits in non-tested portions of the program
data.  Since these portions of the program were not tested explicitly, there was
no evolutionary pressure to purge the harmful edits.  
Delta Debugging eliminates these harmful edits.
%and is the reason for the consistent increase in regression test
%behavior found in the minimized repairs.

\subsubsection{Iterative Repair}
\label{iterative-repair}
The NETGEAR  repairs required two distinct modifications, addressing two different
exploits in a single evolutionary run.  This is an instance of
``iterative repair,'' which has not previously been demonstrated 
real-world extant software.
%FIXME-ERIC: need a citation to iterative repair, probably one of our
%earlier papers that discusses it in future work.
%
% ERIC: I couldn't find any mention of this in the future work of the
% early Gecco or ICSE papers (or the TSE journal paper).  Do you have
% a specific paper in mind?

% \begin{figure}[htb]
%   \centering
%   \includegraphics[bb=0 0 355 248,width=0.46\textwidth]{fitness-improvement.pdf}
%   % \input{fitness-improvement.tex}
%   \caption{Mean fitness as a function of the number of fitness
%     evaluations.  Collected over 10 runs using only the two exploits
%     to access variant fitness.  A fitness of 3 indicates that all
%     three tests are failed but do not throw an error.  A fitness value
%     of 6 passes all three tests.  One exploit is exercised by two
%     tests, so typically a run fixes either the 1-test or 2-test
%     exploit first, then fixes the second later.  These two different
%     repair scenarios are clearly visible in the graph.}
%   \label{fit-by-time}
% \end{figure}

\section{Related Work}
\label{sec-5}
\subsection{Security}
\label{sec-5-1}
% There has been a significant effort to understand the impacts of
% disclosure of discovered exploits.  Researchers typically must decide
% between public disclosure (termed ``full disclosure'') or private
% disclosure to the vendor of the vulnerable software.  The former
% increases the number of attacks in the short term \cite{arora2006does},
% while the later risks the vendor ignoring the exploit extending the
% life of the exploit.

%FIXME-ERic: LEAD HERE WITH a paragraph on router bugs and patching,
%even if you don't have statistics.

Even major software vendors commonly delay releasing patches to
security exploits.  Microsoft waits until the second Tuesday of every
month (known as ``Patch Tuesday'') to release security patches
\cite{lemos2003microsoft}, leading malicious users to release new
exploits on the second Wednesday of every month (known as ``Exploit
Wednesday'') to maximize the time before a patch is released.

In a study of high and medium risk vulnerabilities in Microsoft and
Apple products between 2002 and 2008, about 10\% of
vulnerabilities were found not to be patched within 150 days of
disclosure, and on any given date about 10 vulnerabilities and over 20
vulnerabilities were public and un-patched for Microsoft and Apple
respectively \cite{frei20080}.

FIXME: more related security work.

\subsection{Evolutionary Computation}
\label{sec-5-2}

FIXME: EC background

\subsection{Automated Program Repair}
\label{sec-5-3}

FIXME

\begin{itemize}
\item genprog
\item clearview
\item semfix
\end{itemize}

\section{Discussion}
\label{sec-6}
This technique demonstrates the ability of end users to fix software
exploits in closed source software without any special information or
aid from the software vendor.

%FIXME-ERIC: We need more here.  I'd suggest putting a paragraph here
%about trend towards software-defined networks and what that might
%mean for router bugs and our ability to fix them.

\subsection{Threats to Validity}
\label{sec-6-1}
This initial work is based upon a single exploit repair so it is
possible that the results indicating the effectiveness of repair
without any regression test suite will not generalize.  However, the
authors do not believe that these results are based on any property
unique to the NETGEAR exploits. Rather, we believe that the ability of
the evolutionary repair algorithm to find functional repairs without
the use of any regression test suite is due to both the beneficial
impact of minimization, and to the natural mutational robustness of
software. Specifically, Schulte \emph{et al.}~\cite{schulte2013software} 
find that the functionality of software mutants differs by only about 60\%
between software tested with an empty regression test suites and software
tested with the best obtainable quality regression test suites.

\subsection{Next Steps}
\label{sec-6-2}

\begin{itemize}
\item operation directly on a binary image
\begin{itemize}
\item would require better virtualization
\item would require better fault localization
\end{itemize}
\item proactive hardening
\begin{itemize}
\item shutting off (read:breaking) insecure functionality such as
password reset
\item combination with a fuzz tester in a closed exploit/repair loop
\end{itemize}
\item distributed diversity
\begin{itemize}
\item self certifying patches
\end{itemize}
\item Use ``neutral'' mutations to mask the important aspects of a
  patch to avoid patch reverse-engineering.  As this work demonstrates
  there are often hundreds of extra mutations.
\end{itemize}

\section{Acknowledgments}
\label{sec-7}
Foremost we'd like to thank Zachary Cutlip who analyzed and announced
the NETGEAR exploits, and who helped us to reproduce the exploits
locally.  Without his help this work would not have been possible.  We
would also like to thank Mark Harman for discussion of program repair
without a regression test suite, and Stephen Harding for initially
formulating the interactive lazy regression repair algorithm.

Also, GRANTS GRANTS GRANTS.

\bibliographystyle{plain}
\bibliography{netgear-repair}

\end{document}
